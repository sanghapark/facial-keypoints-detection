{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pandas.io.parsers import read_csv\n",
    "import datetime as dt\n",
    "import time\n",
    "from PIL import Image\n",
    "from K.utils.load import load_test_data\n",
    "from K.utils.models import load_models_with_weights\n",
    "from K.utils.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols01 = [\n",
    "    'left_eye_center_x',            'left_eye_center_y',\n",
    "    'right_eye_center_x',           'right_eye_center_y',\n",
    "    'nose_tip_x',                   'nose_tip_y',\n",
    "    'mouth_center_bottom_lip_x',    'mouth_center_bottom_lip_y'\n",
    "]\n",
    "cols02 = [\n",
    "\n",
    "    'left_eye_inner_corner_x',      'left_eye_inner_corner_y',\n",
    "    'left_eye_outer_corner_x',      'left_eye_outer_corner_y',\n",
    "    'right_eye_inner_corner_x',     'right_eye_inner_corner_y',\n",
    "    'right_eye_outer_corner_x',     'right_eye_outer_corner_y',\n",
    "    'left_eyebrow_inner_end_x',     'left_eyebrow_inner_end_y',\n",
    "    'left_eyebrow_outer_end_x',     'left_eyebrow_outer_end_y',\n",
    "    'right_eyebrow_inner_end_x',    'right_eyebrow_inner_end_y',\n",
    "    'right_eyebrow_outer_end_x',    'right_eyebrow_outer_end_y',\n",
    "\n",
    "    'mouth_left_corner_x',          'mouth_left_corner_y',\n",
    "    'mouth_right_corner_x',         'mouth_right_corner_y',\n",
    "    'mouth_center_top_lip_x',       'mouth_center_top_lip_y'\n",
    "]\n",
    "\n",
    "keypoints = [\n",
    "    'left_eye_center_x', 'left_eye_center_y',\n",
    "    'right_eye_center_x', 'right_eye_center_y',\n",
    "    'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "    'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "    'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "    'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "    'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "    'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "    'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "    'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "    'nose_tip_x', 'nose_tip_y',\n",
    "    'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "    'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "    'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "    'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'\n",
    "]\n",
    "\n",
    "keypoints_indexes = {'left_eye_center_x': 0, 'left_eye_center_y': 1,\n",
    "                  'right_eye_center_x': 2, 'right_eye_center_y': 3,\n",
    "                  'left_eye_inner_corner_x': 4, 'left_eye_inner_corner_y': 5,\n",
    "                  'left_eye_outer_corner_x': 6, 'left_eye_outer_corner_y': 7,\n",
    "                  'right_eye_inner_corner_x': 8, 'right_eye_inner_corner_y': 9,\n",
    "                  'right_eye_outer_corner_x': 10, 'right_eye_outer_corner_y': 11,\n",
    "                  'left_eyebrow_inner_end_x': 12, 'left_eyebrow_inner_end_y': 13,\n",
    "                  'left_eyebrow_outer_end_x': 14, 'left_eyebrow_outer_end_y': 15,\n",
    "                  'right_eyebrow_inner_end_x': 16, 'right_eyebrow_inner_end_y': 17,\n",
    "                  'right_eyebrow_outer_end_x': 18, 'right_eyebrow_outer_end_y': 19,\n",
    "                  'nose_tip_x': 20, 'nose_tip_y': 21,\n",
    "                  'mouth_left_corner_x': 22, 'mouth_left_corner_y': 23,\n",
    "                  'mouth_right_corner_x': 24, 'mouth_right_corner_y': 25,\n",
    "                  'mouth_center_top_lip_x': 26, 'mouth_center_top_lip_y': 27,\n",
    "                  'mouth_center_bottom_lip_x': 28, 'mouth_center_bottom_lip_y': 29}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(values, group, df):\n",
    "    for index, row in group.iterrows():\n",
    "        values.append((df[int(row['ImageId']) - 1][keypoints_indexes[row['FeatureName']]]))\n",
    "    return values\n",
    "\n",
    "def predict(X, model):\n",
    "    Y_hat01, Y_hat02 = np.zeros((X.shape[0], 8)), np.zeros((X.shape[0], 22))\n",
    "    for submodel in model:\n",
    "        for idx, cnn in enumerate(submodel):\n",
    "            Y_hat = cnn.predict(X)\n",
    "            if Y_hat.shape[1] == 8:\n",
    "                Y_hat01 += Y_hat\n",
    "            elif Y_hat.shape[1] == 22:\n",
    "                Y_hat02 += Y_hat\n",
    "    if model[0][0].outputs[0].shape[1] == 8:\n",
    "        Y_hat01 = Y_hat01 / len(model[0])\n",
    "    if model[1][0].outputs[0].shape[1] == 22:\n",
    "        Y_hat02 = Y_hat02 / len(model[1])\n",
    "\n",
    "    Y_hat01 = Y_hat01 * 48 + 48\n",
    "    Y_hat02 = Y_hat02 * 48 + 48\n",
    "    \n",
    "    df01 = pd.DataFrame(Y_hat01, columns=cols01)\n",
    "    df02 = pd.DataFrame(Y_hat02, columns=cols02)\n",
    "    df_merged = pd.concat([df01, df02], axis=1)\n",
    "    df_merged = df_merged[keypoints]\n",
    "    return df_merged.values\n",
    "\n",
    "def predict_with_cnn_cv2(X, model):\n",
    "    face_classifier = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    Y_hat01, Y_hat02 = np.zeros((X.shape[0], 8)), np.zeros((X.shape[0], 22))\n",
    "    for idx, x in enumerate(X):\n",
    "        x = x.reshape(1, 96, 96, 1)\n",
    "\n",
    "        img = to_img(x.reshape(-1)*255)\n",
    "        cv2_img = np.array(img)[:, :, ::-1].copy()\n",
    "        cv2_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(cv2_img, 1.01, 9)\n",
    "        \n",
    "        y_hat01, y_hat02 = np.zeros((1, 8)), np.zeros((1, 22))\n",
    "        for submodel in model:\n",
    "            for cnn in submodel:\n",
    "                \n",
    "                if len(faces) == 1:\n",
    "                    box_x, box_y, box_w, box_h = faces[0]\n",
    "\n",
    "                    detected_face = cv2_img[box_y:box_y+box_h, box_x:box_x+box_w]\n",
    "                    scale = box_w/96\n",
    "                    reshaped = np.reshape(cv2.resize(detected_face, (96, 96)), (1, 96, 96, 1))\n",
    "                    normalized = reshaped / 255\n",
    "                    \n",
    "                    cropped_y_hat = cnn.predict(normalized)\n",
    "                    cropped_y_hat = (cropped_y_hat * 48 + 48) * scale\n",
    "                    cropped_y_hat[0, 0::2] += box_x\n",
    "                    cropped_y_hat[0, 1::2] += box_y\n",
    "                    if cropped_y_hat.shape[1] == 8:\n",
    "                        y_hat01 += cropped_y_hat\n",
    "                    elif cropped_y_hat.shape[1] == 22:\n",
    "                        y_hat02 += cropped_y_hat\n",
    "                else:\n",
    "                    y_hat = cnn.predict(x.reshape(-1, 96, 96, 1)) * 48 + 48\n",
    "                    if y_hat.shape[1] == 8:\n",
    "                        y_hat01 += y_hat\n",
    "                    elif y_hat.shape[1] == 22:\n",
    "                        y_hat02 += y_hat\n",
    "        Y_hat01[idx] = y_hat01\n",
    "        Y_hat02[idx] = y_hat02\n",
    "\n",
    "    if model[0][0].outputs[0].shape[1] == 8:\n",
    "        Y_hat01 = Y_hat01 / len(model[0])\n",
    "    if model[1][0].outputs[0].shape[1] == 22:\n",
    "        Y_hat02 = Y_hat02 / len(model[1])\n",
    "    df01 = pd.DataFrame(Y_hat01, columns=cols01)\n",
    "    df02 = pd.DataFrame(Y_hat02, columns=cols02)\n",
    "    df_merged = pd.concat([df01, df02], axis=1)\n",
    "    df_merged = df_merged[keypoints]\n",
    "    return df_merged.values\n",
    "\n",
    "\n",
    "def predict_with_cnn_cv3(X, model):\n",
    "    face_classifier = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    Y_hat01, Y_hat02 = np.zeros((X.shape[0], 8)), np.zeros((X.shape[0], 22))\n",
    "    for idx, x in enumerate(X):\n",
    "        x = x.reshape(1, 96, 96, 1)\n",
    "\n",
    "        img = to_img(x.reshape(-1)*255)\n",
    "        cv2_img = np.array(img)[:, :, ::-1].copy()\n",
    "        cv2_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(cv2_img, 1.01, 9)\n",
    "        \n",
    "        y_hat01, y_hat02 = np.zeros((1, 8)), np.zeros((1, 22))\n",
    "        y_hat01_cv2, y_hat02_cv2 = np.zeros((1, 8)), np.zeros((1, 22))\n",
    "        found_face = False\n",
    "        for submodel in model:\n",
    "            for cnn in submodel:\n",
    "                \n",
    "                y_hat = cnn.predict(x.reshape(-1, 96, 96, 1)) * 48 + 48\n",
    "                if y_hat.shape[1] == 8:\n",
    "                    y_hat01 += y_hat\n",
    "                elif y_hat.shape[1] == 22:\n",
    "                    y_hat02 += y_hat\n",
    "                \n",
    "                if len(faces) == 1:\n",
    "                    found_face = True\n",
    "                    box_x, box_y, box_w, box_h = faces[0]\n",
    "\n",
    "                    detected_face = cv2_img[box_y:box_y+box_h, box_x:box_x+box_w]\n",
    "                    scale = box_w/96\n",
    "                    reshaped = np.reshape(cv2.resize(detected_face, (96, 96)), (1, 96, 96, 1))\n",
    "                    normalized = reshaped / 255\n",
    "                    \n",
    "                    cropped_y_hat = cnn.predict(normalized)\n",
    "                    cropped_y_hat = (cropped_y_hat * 48 + 48) * scale\n",
    "                    cropped_y_hat[0, 0::2] += box_x\n",
    "                    cropped_y_hat[0, 1::2] += box_y\n",
    "                    if cropped_y_hat.shape[1] == 8:\n",
    "                        y_hat01_cv2 += cropped_y_hat\n",
    "                    elif cropped_y_hat.shape[1] == 22:\n",
    "                        y_hat02_cv2 += cropped_y_hat\n",
    "                \n",
    "        if found_face:\n",
    "            if y_hat01[0][7] > y_hat01_cv2[0][7]:\n",
    "                print(\"using cnn over cnncv2\")\n",
    "            Y_hat01[idx] = y_hat01 if y_hat01[0][7] > y_hat01_cv2[0][7] else y_hat01_cv2\n",
    "            Y_hat02[idx] = y_hat02 if y_hat02[0][7] > y_hat02_cv2[0][7] else y_hat02_cv2\n",
    "        else:\n",
    "            Y_hat01[idx] = y_hat01\n",
    "            Y_hat02[idx] = y_hat02\n",
    "\n",
    "    if model[0][0].outputs[0].shape[1] == 8:\n",
    "        Y_hat01 = Y_hat01 / len(model[0])\n",
    "    if model[1][0].outputs[0].shape[1] == 22:\n",
    "        Y_hat02 = Y_hat02 / len(model[1])\n",
    "    df01 = pd.DataFrame(Y_hat01, columns=cols01)\n",
    "    df02 = pd.DataFrame(Y_hat02, columns=cols02)\n",
    "    df_merged = pd.concat([df01, df02], axis=1)\n",
    "    df_merged = df_merged[keypoints]\n",
    "    return df_merged.values\n",
    "\n",
    "def create_submission(predicted):\n",
    "    reader = read_csv('./data/IdLookUpTable.csv')\n",
    "    grouped = reader.groupby('ImageId')\n",
    "    values = []\n",
    "    for name, group in grouped:\n",
    "        loop(values, group, predicted)\n",
    "    submission = pd.DataFrame({'Location': values})\n",
    "    submission.index += 1\n",
    "    return submission\n",
    "\n",
    "def pick_cnns(model, indexes_dataset01, indexes_dataset02):\n",
    "    cnns_dataset01 = [model[0][i] for i in indexes_dataset01]\n",
    "    cnns_dataset02 = [model[1][i] for i in indexes_dataset02]\n",
    "    return [cnns_dataset01, cnns_dataset02]\n",
    "\n",
    "def plot_loss_history(model_name, submodel_name):\n",
    "    for i in range(20):\n",
    "        cnn_name = '{}_{:02}'.format(submodel_name, i)\n",
    "        loss_history = pd.read_csv('K/models/{}/{}/{}_{:02}.csv'.format(model_name, submodel_name, submodel_name, i))\n",
    "        plt.plot(loss_history['rmse'])\n",
    "        plt.plot(loss_history['val_rmse'])\n",
    "        plt.title(cnn_name)\n",
    "        plt.ylabel('rmse')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper right')\n",
    "        axes = plt.gca()\n",
    "#         axes.set_ylim([0,10])\n",
    "        plt.show()\n",
    "    \n",
    "def to_img(x):\n",
    "    img_size = 96\n",
    "    img = Image.new(\"RGB\", (img_size, img_size), \"black\") \n",
    "    pixels = img.load()\n",
    "    for i in range(img_size):\n",
    "        for j in range(img_size):\n",
    "            pixels[i,j] = (x[i+j*img_size], x[i+j*img_size], x[i+j*img_size])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_name = 'model_20171117_1723'\n",
    "X_test = load_test_data('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_models_with_weights(model_name)\n",
    "predicted = predict(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = create_submission(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "filename = 'submission_' + datetime + '.csv'\n",
    "submission.to_csv(filename, index_label='RowId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission_20171120_0110.csv\n",
    "* RMSE: <strong>2.57497</strong>\n",
    "* 보완 할 점\n",
    "  * 가장 퍼포먼스가 좋은 CNN을 선택 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss_history(model_name, 'cnn2_dataset01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss_history(model_name, 'cnn2_dataset02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataset01에 대한 서브모델에서 가장 좋은 성은은 cnn2_Dataset01_04\n",
    "* Dataset02에 대한 서브모델에서 가장 좋은 성은은 cnn2_Dataset02_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ones = pick_cnns(model, [4], [25])\n",
    "predicted = predict(X_test, best_cnns)\n",
    "submission = create_submission(predicted)\n",
    "datetime = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "filename = 'submission_' + datetime + '.csv'\n",
    "submission.to_csv(filename, index_label='RowId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission_20171120_0116.csv\n",
    "* RMSE: <strong>2.25358</strong>\n",
    "* 보완 할 점\n",
    "  * 성능 좋은 애들로 모아서 앙상블 모델을 만들어서 예측해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes08 = [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19] \n",
    "indexes22 = [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 15, 18, 21, 22, 25, 27, 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ensemble = pick_cnns(model, indexes08, indexes22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict(X_test, selected_ensemble)\n",
    "submission = create_submission(predicted)\n",
    "datetime = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "filename = 'submission_' + datetime + '.csv'\n",
    "submission.to_csv(filename, index_label='RowId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission_20171120_0132.csv\n",
    "* RMSE: <strong>2.14311</strong>\n",
    "* 보완 할 점\n",
    "  * OpenCV2로 얼굴을 인식하여 Face Bounding Box를 찾고 그 안에서 예측해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(X_test))\n",
    "print(idx)\n",
    "\n",
    "img = to_img(X_test[idx].reshape(-1)*255)\n",
    "\n",
    "cv2_img = np.array(img)[:, :, ::-1].copy()\n",
    "cv2_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2GRAY)\n",
    "image_with_detections = np.copy(cv2_img)\n",
    "    \n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('image')    \n",
    "\n",
    "landmarks2 = predict_with_cnn_cv2(np.array([X_test[idx]]), selected_ensemble)\n",
    "ax1.scatter(landmarks2[0, 0::2], landmarks2[0, 1::2], marker='o', c='c', s=15)\n",
    "\n",
    "landmarks =  predict_with_cnn_cv3(X_test[idx].reshape(-1, 96, 96, 1), selected_ensemble)\n",
    "ax1.scatter(landmarks[0, 0::2], landmarks[0, 1::2], marker='o', c='r', s=15)\n",
    "\n",
    "ax1.imshow(image_with_detections, cmap='gray')\n",
    "\n",
    "# 어이없는 사진들\n",
    "# 956(전신초상화), 694, 1064, 951(얼굴 두개)\n",
    "\n",
    "# 어려운 사진들\n",
    "# 962(흑인원주민), 511클로즈업\n",
    "\n",
    "# 대체적으로 얼굴이 기울어 있거나 옆모습 화질이 안좋은 이미지 같은 경우는 OpenCV2로 인식해서 예측하면 저 좋음\n",
    "# ex) 1427, 1615, 960, 1192\n",
    "\n",
    "# 얼굴 일부분이 잘려 있는 경우 OpenCV2같은 경우 얼굴을 인식을 잘 못해서 잘못된 얼굴 인식부분에서 예측해서 안 좋음\n",
    "# ex) 310, 428\n",
    "# 얼굴예측한 부분이 너무 작으면 cnn것을 사용하자\n",
    "\n",
    "# 사진에 얼굴이 두개 있는 경우는 어떻게 해야 할까? \n",
    "# NA로 채워서 보내보자\n",
    "\n",
    "# cnn이 cnncv2보다 좋은 성능 내는 사진들\n",
    "# 216, 714, 835, 1586, 1342\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted = predict_with_cnn_cv2(X_test, selected_ensemble)\n",
    "submission = create_submission(predicted)\n",
    "datetime = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "filename = 'submission_' + datetime + '.csv'\n",
    "submission.to_csv(filename, index_label='RowId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission_20171120_1719.csv\n",
    "* RMSE: <strong>2.83592</strong>\n",
    "* 사진들 퀄리티가 안 좋은 사진들이 많아서 False Positive가 잦게 발생.\n",
    "* 엉뚱한 곳에서 Keypoints를 찾는 경우가 생겨서 오히려 퍼포먼스가 안 좋아짐.\n",
    "* 보완 할 점\n",
    "  * OpenCV를 이용하는 것은 그만 두자.\n",
    "  * 더 다양한 데이터 오그멘테이션을 추가 하여 다시 트레이닝 시켜보자.\n",
    "    * Elastic Transformation\n",
    "    * Perspective Transformation\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
